{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths for datasets\n",
    "noise_folder = './noise'\n",
    "unknown_folder = './unknown'\n",
    "kha_folder = './kha'\n",
    "\n",
    "# Load .wav files into dataset\n",
    "def load_wav_files(folder):\n",
    "    dataset = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            audio, sr = librosa.load(file_path, sr=None)\n",
    "            dataset.append(audio)\n",
    "    return dataset\n",
    "\n",
    "# Load datasets\n",
    "noise_dataset = load_wav_files(noise_folder)\n",
    "unknown_dataset = load_wav_files(unknown_folder)\n",
    "kha_dataset = load_wav_files(kha_folder)\n",
    "\n",
    "# Data augmentation functions\n",
    "def time_stretch(audio, rate):\n",
    "    \"\"\"Time stretch the audio by the given rate.\"\"\"\n",
    "    return librosa.effects.time_stretch(audio, rate=rate)\n",
    "\n",
    "def pitch_shift(audio, sr, n_steps):\n",
    "    \"\"\"Shift the pitch of the audio by n_steps semitones.\"\"\"\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def add_noise(audio, noise_factor=0.005):\n",
    "    \"\"\"Add random noise to the audio.\"\"\"\n",
    "    noise = np.random.randn(len(audio)) * noise_factor\n",
    "    return audio + noise\n",
    "\n",
    "# Augment Kha dataset\n",
    "def augment_kha_data(kha_data):\n",
    "    augmented_data = []\n",
    "    sr = 16000  # Set sample rate\n",
    "\n",
    "    for audio in kha_data:\n",
    "        # Original audio\n",
    "        augmented_data.append(audio)\n",
    "\n",
    "        # Time stretching\n",
    "        for rate in np.arange(0.8, 1.3, 0.1):  # Stretching from 0.8 to 1.2\n",
    "            augmented_data.append(time_stretch(audio, rate))\n",
    "\n",
    "        # # Pitch shifting\n",
    "        # for n_steps in range(-3, 4):  # Shift pitch from -3 to +3 semitones\n",
    "        #     augmented_data.append(pitch_shift(audio, sr, n_steps))\n",
    "\n",
    "        # Adding noise\n",
    "        augmented_data.append(add_noise(audio))\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Function to save augmented audio data into subfolders\n",
    "def save_augmented_data(augmented_kha, noise_data, unknown_data, folder_kha, folder_noise, folder_unknown, base_name='augmented'):\n",
    "    os.makedirs(folder_kha, exist_ok=True)  # Create Kha folder\n",
    "    os.makedirs(folder_noise, exist_ok=True)  # Create Noise folder\n",
    "    os.makedirs(folder_unknown, exist_ok=True)  # Create Unknown folder\n",
    "    \n",
    "    # Save Kha augmented data\n",
    "    for i, audio in enumerate(augmented_kha):\n",
    "        file_path = os.path.join(folder_kha, f'{base_name}_{i}.wav')\n",
    "        sf.write(file_path, audio, 16000)  # Save the audio file\n",
    "\n",
    "    # Save Noise dataset\n",
    "    for i, audio in enumerate(noise_data):\n",
    "        file_path = os.path.join(folder_noise, f'noise_{i}.wav')\n",
    "        sf.write(file_path, audio, 16000)  # Save the audio file\n",
    "\n",
    "    # Save Unknown dataset\n",
    "    for i, audio in enumerate(unknown_data):\n",
    "        file_path = os.path.join(folder_unknown, f'unknown_{i}.wav')\n",
    "        sf.write(file_path, audio, 16000)  # Save the audio file\n",
    "\n",
    "# Augment the Kha dataset\n",
    "augmented_kha_dataset = augment_kha_data(kha_dataset)\n",
    "\n",
    "# # Save augmented audio files to respective subfolders\n",
    "# save_augmented_data(augmented_kha_dataset, noise_dataset, unknown_dataset, './balanced_dataset/kha', './balanced_dataset/noise', './balanced_dataset/unknown')\n",
    "\n",
    "# # Convert Kha dataset to a numerical format for ADASYN\n",
    "# X_kha = [librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=13) for audio in augmented_kha_dataset]\n",
    "\n",
    "# # Define a fixed length for MFCC features\n",
    "# fixed_length = 100  # Adjust this based on your requirements\n",
    "\n",
    "# # Pad or truncate MFCC features to ensure consistent shapes for Kha\n",
    "# X_kha_flat = np.array([np.pad(x, ((0, 0), (0, fixed_length - x.shape[1])), mode='constant') if x.shape[1] < fixed_length else x[:, :fixed_length] for x in X_kha])\n",
    "\n",
    "# # Flatten the MFCC features into 2D array for Kha\n",
    "# X_kha_flat = np.array([x.flatten() for x in X_kha_flat])\n",
    "\n",
    "# # Prepare labels for Kha dataset\n",
    "# y_kha = ['Kha'] * len(X_kha_flat)\n",
    "\n",
    "# # Extract MFCC features for noise and unknown datasets\n",
    "# X_noise = [librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=13) for audio in noise_dataset]\n",
    "# X_unknown = [librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=13) for audio in unknown_dataset]\n",
    "\n",
    "# # Pad or truncate MFCC features for noise dataset\n",
    "# X_noise_flat = np.array([np.pad(x, ((0, 0), (0, fixed_length - x.shape[1])), mode='constant') if x.shape[1] < fixed_length else x[:, :fixed_length] for x in X_noise])\n",
    "\n",
    "# # Pad or truncate MFCC features for unknown dataset\n",
    "# X_unknown_flat = np.array([np.pad(x, ((0, 0), (0, fixed_length - x.shape[1])), mode='constant') if x.shape[1] < fixed_length else x[:, :fixed_length] for x in X_unknown])\n",
    "\n",
    "# # Flatten the MFCC features for noise and unknown datasets\n",
    "# X_noise_flat = np.array([x.flatten() for x in X_noise_flat])\n",
    "# X_unknown_flat = np.array([x.flatten() for x in X_unknown_flat])\n",
    "\n",
    "# # Combine the datasets\n",
    "# X_combined = np.concatenate((X_kha_flat, X_noise_flat, X_unknown_flat), axis=0)\n",
    "# y_combined = y_kha + ['noise'] * len(X_noise_flat) + ['unknown'] * len(X_unknown_flat)\n",
    "\n",
    "# # Implement ADASYN for oversampling the minority class\n",
    "# adasyn = ADASYN(sampling_strategy='minority', n_neighbors=5)\n",
    "# X_resampled, y_resampled = adasyn.fit_resample(X_combined, y_combined)\n",
    "\n",
    "# # Output shape verification\n",
    "# print(f\"Kha resampled dataset size: {len(y_resampled)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Kha dataset size: 360\n",
      "Augmented audio files saved successfully in 'kha_augmented' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Define folder paths for datasets\n",
    "noise_folder = './noise'\n",
    "unknown_folder = './unknown'\n",
    "kha_folder = './kha'\n",
    "\n",
    "# Load .wav files into dataset\n",
    "def load_wav_files(folder):\n",
    "    dataset = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(folder, filename)\n",
    "            audio, sr = librosa.load(file_path, sr=None)\n",
    "            dataset.append(audio)\n",
    "    return dataset\n",
    "\n",
    "# Load datasets\n",
    "noise_dataset = load_wav_files(noise_folder)\n",
    "unknown_dataset = load_wav_files(unknown_folder)\n",
    "kha_dataset = load_wav_files(kha_folder)\n",
    "\n",
    "# Smart truncate or pad function\n",
    "def truncate_or_pad_smart(audio, sr, target_length_ms=1000):\n",
    "    target_length_samples = int((target_length_ms / 1000) * sr)  # Convert ms to samples\n",
    "    if len(audio) < target_length_samples:\n",
    "        # Pad audio with zeros if it's shorter than target length\n",
    "        padding = target_length_samples - len(audio)\n",
    "        audio = np.pad(audio, (0, padding), 'constant')\n",
    "    else:\n",
    "        # Calculate short-term energy without reshaping\n",
    "        segment_length = sr // 10\n",
    "        num_segments = len(audio) // segment_length\n",
    "        short_time_energy = np.array([np.sum(np.square(audio[i*segment_length:(i+1)*segment_length])) for i in range(num_segments)])\n",
    "        \n",
    "        # Find the peak energy index\n",
    "        peak_index = np.argmax(short_time_energy)  \n",
    "        \n",
    "        # Calculate the segment to keep around the peak index\n",
    "        start = max(0, peak_index * segment_length - target_length_samples // 2)\n",
    "        audio = audio[start:start + target_length_samples]  # Truncate audio around the main voice\n",
    "    return audio\n",
    "\n",
    "# Advanced time stretching using Phase Vocoder\n",
    "def advanced_time_stretch(audio, rate, sr=16000):\n",
    "    # Apply time stretching using librosa's phase vocoder\n",
    "    stretched_audio = librosa.effects.time_stretch(audio, rate=rate)\n",
    "    return truncate_or_pad_smart(stretched_audio, sr)\n",
    "\n",
    "# Augment Kha dataset\n",
    "def augment_kha_data(kha_data):\n",
    "    augmented_data = []\n",
    "    sr = 16000  # Set sample rate\n",
    "\n",
    "    for audio in kha_data:\n",
    "        # Original audio\n",
    "        augmented_data.append(truncate_or_pad_smart(audio, sr))\n",
    "\n",
    "        # Time stretching\n",
    "        for rate in np.arange(0.75, 1.2, 0.1):  # Stretching from 0.7 to 1.1\n",
    "            augmented_data.append(advanced_time_stretch(audio, rate, sr))\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "# Create a new folder name starting with 'kha' to save augmented data\n",
    "new_folder = './kha_augmented'\n",
    "os.makedirs(new_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "# Augment the Kha dataset\n",
    "augmented_kha_dataset = augment_kha_data(kha_dataset)\n",
    "\n",
    "# Save augmented audio files to the new folder\n",
    "for i, audio in enumerate(augmented_kha_dataset):\n",
    "    file_path = os.path.join(new_folder, f'augmented_{i}.wav')\n",
    "    sf.write(file_path, audio, 16000)  # Save the audio file\n",
    "\n",
    "# Output verification\n",
    "print(f\"Augmented Kha dataset size: {len(augmented_kha_dataset)}\")\n",
    "print(\"Augmented audio files saved successfully in 'kha_augmented' folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
